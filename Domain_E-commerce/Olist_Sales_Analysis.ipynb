{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c48381",
   "metadata": {},
   "source": [
    "# Capstone Project (E-commerce Domain)\n",
    "                               Project Name: Olist Marketplace Sales Data Analysis\n",
    "                                             Prepared by: Bishowjith Ghosh\n",
    "                                                  Date: September 2024\n",
    "                                          Master’s Program in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb48b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cd1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8f143",
   "metadata": {},
   "source": [
    "# Load all Olist datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab4b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('olist_orders_dataset.csv')\n",
    "customers = pd.read_csv('olist_customers_dataset.csv')\n",
    "geolocation = pd.read_csv('olist_geolocation_dataset.csv')\n",
    "order_items = pd.read_csv('olist_order_items_dataset.csv')\n",
    "order_payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
    "order_reviews = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "products = pd.read_csv('olist_products_dataset.csv')\n",
    "sellers = pd.read_csv('olist_sellers_dataset.csv')\n",
    "product_categories = pd.read_csv('product_category_name_translation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb1d1e",
   "metadata": {},
   "source": [
    "# Preview the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31311c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n",
      "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                         1037       -23.545621       -46.639292   \n",
      "1                         1046       -23.546081       -46.644820   \n",
      "2                         1046       -23.546129       -46.642951   \n",
      "3                         1041       -23.544392       -46.639499   \n",
      "4                         1035       -23.541578       -46.641607   \n",
      "\n",
      "  geolocation_city geolocation_state  \n",
      "0        sao paulo                SP  \n",
      "1        sao paulo                SP  \n",
      "2        sao paulo                SP  \n",
      "3        sao paulo                SP  \n",
      "4        sao paulo                SP  \n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n",
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n",
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4                  NaN   \n",
      "1             5                  NaN   \n",
      "2             5                  NaN   \n",
      "3             5                  NaN   \n",
      "4             5                  NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                                NaN  2018-01-18 00:00:00   \n",
      "1                                                NaN  2018-03-10 00:00:00   \n",
      "2                                                NaN  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n",
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n",
      "                          seller_id  seller_zip_code_prefix  \\\n",
      "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
      "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
      "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
      "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
      "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
      "\n",
      "         seller_city seller_state  \n",
      "0           campinas           SP  \n",
      "1         mogi guacu           SP  \n",
      "2     rio de janeiro           RJ  \n",
      "3          sao paulo           SP  \n",
      "4  braganca paulista           SP  \n",
      "    product_category_name product_category_name_english\n",
      "0            beleza_saude                 health_beauty\n",
      "1  informatica_acessorios         computers_accessories\n",
      "2              automotivo                          auto\n",
      "3         cama_mesa_banho                bed_bath_table\n",
      "4        moveis_decoracao               furniture_decor\n"
     ]
    }
   ],
   "source": [
    "print(orders.head())\n",
    "print(customers.head())\n",
    "print(geolocation.head())\n",
    "print(order_items.head())\n",
    "print(order_payments.head())\n",
    "print(order_reviews.head())\n",
    "print(products.head())\n",
    "print(sellers.head())\n",
    "print(product_categories.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c2463",
   "metadata": {},
   "source": [
    "# Cheecking Datatypes for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a1ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object\n",
      "customer_id                 object\n",
      "customer_unique_id          object\n",
      "customer_zip_code_prefix     int64\n",
      "customer_city               object\n",
      "customer_state              object\n",
      "dtype: object\n",
      "geolocation_zip_code_prefix      int64\n",
      "geolocation_lat                float64\n",
      "geolocation_lng                float64\n",
      "geolocation_city                object\n",
      "geolocation_state               object\n",
      "dtype: object\n",
      "order_id                object\n",
      "order_item_id            int64\n",
      "product_id              object\n",
      "seller_id               object\n",
      "shipping_limit_date     object\n",
      "price                  float64\n",
      "freight_value          float64\n",
      "dtype: object\n",
      "order_id                 object\n",
      "payment_sequential        int64\n",
      "payment_type             object\n",
      "payment_installments      int64\n",
      "payment_value           float64\n",
      "dtype: object\n",
      "review_id                  object\n",
      "order_id                   object\n",
      "review_score                int64\n",
      "review_comment_title       object\n",
      "review_comment_message     object\n",
      "review_creation_date       object\n",
      "review_answer_timestamp    object\n",
      "dtype: object\n",
      "product_id                     object\n",
      "product_category_name          object\n",
      "product_name_lenght           float64\n",
      "product_description_lenght    float64\n",
      "product_photos_qty            float64\n",
      "product_weight_g              float64\n",
      "product_length_cm             float64\n",
      "product_height_cm             float64\n",
      "product_width_cm              float64\n",
      "dtype: object\n",
      "seller_id                 object\n",
      "seller_zip_code_prefix     int64\n",
      "seller_city               object\n",
      "seller_state              object\n",
      "dtype: object\n",
      "product_category_name            object\n",
      "product_category_name_english    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types for the orders dataset\n",
    "print(orders.dtypes)\n",
    "\n",
    "# Check data types for all other datasets\n",
    "print(customers.dtypes)\n",
    "print(geolocation.dtypes)\n",
    "print(order_items.dtypes)\n",
    "print(order_payments.dtypes)\n",
    "print(order_reviews.dtypes)\n",
    "print(products.dtypes)\n",
    "print(sellers.dtypes)\n",
    "print(product_categories.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b52b1a",
   "metadata": {},
   "source": [
    "# Data Types Need Corrections "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca967650",
   "metadata": {},
   "source": [
    "1. Orders Dataset: \n",
    "\n",
    "Columns : order_purchase_timestamp, order_approved_at, order_delivered_customer_date, order_delivered_carrier_date\n",
    "\n",
    "Reason: These are date columns, and it’s essential to convert them into the datetime data type to perform any time-based analysis.\n",
    "\n",
    "2. Order Items Dataset: \n",
    "\n",
    "Columns: shipping_limit_dat\n",
    "\n",
    "Reason: shipping_limit_date should be converted from object to datetime to handle shipping deadlines properly.\n",
    "\n",
    "3. Order Reviews Dataset: \n",
    "\n",
    "Columns: review_creation_date, review_answer_timestamp,\n",
    "\n",
    "Reason: These columns are timestamps indicating when reviews were created and answered. They should be converted to the datetime data type for any time-based analysis, such as tracking review response times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8045ad",
   "metadata": {},
   "source": [
    "# Correct Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d7855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                                 object\n",
      "customer_id                              object\n",
      "order_status                             object\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                datetime64[ns]\n",
      "order_delivered_carrier_date     datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n",
      "order_id                       object\n",
      "order_item_id                   int64\n",
      "product_id                     object\n",
      "seller_id                      object\n",
      "shipping_limit_date    datetime64[ns]\n",
      "price                         float64\n",
      "freight_value                 float64\n",
      "dtype: object\n",
      "review_id                          object\n",
      "order_id                           object\n",
      "review_score                        int64\n",
      "review_comment_title               object\n",
      "review_comment_message             object\n",
      "review_creation_date       datetime64[ns]\n",
      "review_answer_timestamp    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Orders Dataset : Columns\n",
    "\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\n",
    "orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\n",
    "\n",
    "# 2. Order Items Dataset: Columns\n",
    "order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'])\n",
    "\n",
    "# 3. Order Reviews Dataset: Columns\n",
    "\n",
    "order_reviews['review_creation_date'] = pd.to_datetime(order_reviews['review_creation_date'])\n",
    "order_reviews['review_answer_timestamp'] = pd.to_datetime(order_reviews['review_answer_timestamp'])\n",
    "\n",
    "\n",
    "# Checking corrected data types \n",
    "print(orders.dtypes)                \n",
    "print(order_items.dtypes)\n",
    "print(order_reviews.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc9bfb",
   "metadata": {},
   "source": [
    "# Checking for missing values in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ad9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Missing Values:\n",
      " order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "Customers Missing Values:\n",
      " customer_id                 0\n",
      "customer_unique_id          0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "dtype: int64\n",
      "Geolocation Missing Values:\n",
      " geolocation_zip_code_prefix    0\n",
      "geolocation_lat                0\n",
      "geolocation_lng                0\n",
      "geolocation_city               0\n",
      "geolocation_state              0\n",
      "dtype: int64\n",
      "Order Items Missing Values:\n",
      " order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "Order Payments Missing Values:\n",
      " order_id                0\n",
      "payment_sequential      0\n",
      "payment_type            0\n",
      "payment_installments    0\n",
      "payment_value           0\n",
      "dtype: int64\n",
      "Order Reviews Missing Values:\n",
      " review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       87656\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n",
      "Products Missing Values:\n",
      " product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "Sellers Missing Values:\n",
      " seller_id                 0\n",
      "seller_zip_code_prefix    0\n",
      "seller_city               0\n",
      "seller_state              0\n",
      "dtype: int64\n",
      "Product Categories Missing Values:\n",
      " product_category_name            0\n",
      "product_category_name_english    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Orders Missing Values:\\n\", orders.isnull().sum())\n",
    "print(\"Customers Missing Values:\\n\", customers.isnull().sum())\n",
    "print(\"Geolocation Missing Values:\\n\", geolocation.isnull().sum())\n",
    "print(\"Order Items Missing Values:\\n\", order_items.isnull().sum())\n",
    "print(\"Order Payments Missing Values:\\n\", order_payments.isnull().sum())\n",
    "print(\"Order Reviews Missing Values:\\n\", order_reviews.isnull().sum())\n",
    "print(\"Products Missing Values:\\n\", products.isnull().sum())\n",
    "print(\"Sellers Missing Values:\\n\", sellers.isnull().sum())\n",
    "print(\"Product Categories Missing Values:\\n\", product_categories.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145835fa",
   "metadata": {},
   "source": [
    "# Handling Missing Values For All Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb87dd",
   "metadata": {},
   "source": [
    "Missing values in Orders Dataset,Order Reviews Dataset, Products Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba73b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Orders Dataset:\n",
    "\n",
    "# order_approved_at:       Fill in the missing order_approved_at values by using the order_purchase_timestamp \n",
    "#                          Or you can drop these rows if approval date is crucial for further analysis.\n",
    "\n",
    "orders['order_approved_at'].fillna(orders['order_purchase_timestamp'], inplace=True)\n",
    "\n",
    "\n",
    "# Drop rows where order_delivered_carrier_date or order_delivered_customer_date is missing\n",
    "orders.dropna(subset=['order_delivered_carrier_date', 'order_delivered_customer_date'], inplace=True)\n",
    "\n",
    "# Check for remaining missing values\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881d1814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                  0\n",
       "order_id                   0\n",
       "review_score               0\n",
       "review_comment_title       0\n",
       "review_comment_message     0\n",
       "review_creation_date       0\n",
       "review_answer_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Order Reviews Dataset:\n",
    "\n",
    "# review_comment_title, review_comment_message:\n",
    "#                     These are textual fields that are not critical for numerical analysis. Fill with placeholders \n",
    "#                     like \"No Title\" or \"No Comment\". Drop rows with missing values if not needed.\n",
    "\n",
    "order_reviews['review_comment_title'].fillna('No Title', inplace=True)\n",
    "order_reviews['review_comment_message'].fillna('No Comment', inplace=True)\n",
    "\n",
    "\n",
    "order_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3861abb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                    0\n",
       "product_category_name         0\n",
       "product_name_lenght           0\n",
       "product_description_lenght    0\n",
       "product_photos_qty            0\n",
       "product_weight_g              0\n",
       "product_length_cm             0\n",
       "product_height_cm             0\n",
       "product_width_cm              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. products Dataset\n",
    "\n",
    "# product_category_name: Since these are categorical fields, fill with a placeholder like \"Unknown\".\n",
    "\n",
    "products['product_category_name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# product_name_length, product_description_length, product_photos_qty, product_weight_g, product_length_cm, \n",
    "# product_height_cm, product_width_cm:   These are Numerical fields.Using mean or median to fill missing numerical values.\n",
    "\n",
    "\n",
    "# Fill missing numerical values with the mean\n",
    "products['product_name_lenght'].fillna(products['product_name_lenght'].mean(), inplace=True)\n",
    "products['product_description_lenght'].fillna(products['product_description_lenght'].mean(), inplace=True)\n",
    "products['product_photos_qty'].fillna(products['product_photos_qty'].mean(), inplace=True)\n",
    "products['product_weight_g'].fillna(products['product_weight_g'].mean(), inplace=True)\n",
    "products['product_length_cm'].fillna(products['product_length_cm'].mean(), inplace=True)\n",
    "products['product_height_cm'].fillna(products['product_height_cm'].mean(), inplace=True)\n",
    "products['product_width_cm'].fillna(products['product_width_cm'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "products.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14706bac",
   "metadata": {},
   "source": [
    "# Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbdd9159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders duplicated: 0\n",
      "customers duplicated: 0\n",
      "geolocation duplicated: 261831\n",
      "order_items duplicated: 0\n",
      "order_payments duplicated: 0\n",
      "order_reviews duplicatedn 0\n",
      "products duplicated 0\n",
      "sellers duplicated: 0\n"
     ]
    }
   ],
   "source": [
    "print( \"orders duplicated:\", orders.duplicated().sum())\n",
    "print(\"customers duplicated:\", customers.duplicated().sum())\n",
    "print(\"geolocation duplicated:\", geolocation.duplicated().sum())\n",
    "print(\"order_items duplicated:\", order_items.duplicated().sum())\n",
    "print(\"order_payments duplicated:\", order_payments.duplicated().sum())\n",
    "print(\"order_reviews duplicatedn\", order_reviews.duplicated().sum())\n",
    "print(\"products duplicated\", products.duplicated().sum())\n",
    "print(\"sellers duplicated:\", sellers.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fe259",
   "metadata": {},
   "source": [
    "# Remove Duplicates in the Geolocation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5b384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geolocation_cleaned.duplicated : 0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the geolocation dataset\n",
    "geolocation_cleaned = geolocation.drop_duplicates()\n",
    "\n",
    "# Confirm the duplicates have been removed\n",
    "print(\"geolocation_cleaned.duplicated :\", geolocation_cleaned.duplicated().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a03109",
   "metadata": {},
   "source": [
    "# Data Cleaning,Trimming Whitespaces and Handling Case Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0c24e",
   "metadata": {},
   "source": [
    "Check for Whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b11aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders - Customer ID (leading/trailing whitespaces):\n",
      "Series([], Name: customer_id, dtype: object)\n",
      "Order Items - Product ID (leading/trailing whitespaces):\n",
      "Series([], Name: product_id, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Check for rows with leading/trailing whitespaces in the customer_id column\n",
    "print(\"Orders - Customer ID (leading/trailing whitespaces):\")\n",
    "print(orders[orders['customer_id'].str.contains('^\\s+|\\s+$', regex=True)]['customer_id'].head())\n",
    "\n",
    "# Check for rows with leading/trailing whitespaces in the product_id column\n",
    "print(\"Order Items - Product ID (leading/trailing whitespaces):\")\n",
    "print(order_items[order_items['product_id'].str.contains('^\\s+|\\s+$', regex=True)]['product_id'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6419e9",
   "metadata": {},
   "source": [
    "Check for Case Sensitivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50551608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders - Customer ID (case inconsistencies):\n",
      "Series([], Name: customer_id, dtype: object)\n",
      "Order Items - Product ID (case inconsistencies):\n",
      "Series([], Name: product_id, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Check for case inconsistencies in customer_id (uppercase letters)\n",
    "print(\"Orders - Customer ID (case inconsistencies):\")\n",
    "print(orders[orders['customer_id'].str.contains('[A-Z]')]['customer_id'].head())\n",
    "\n",
    "# Check for case inconsistencies in product_id (uppercase letters)\n",
    "print(\"Order Items - Product ID (case inconsistencies):\")\n",
    "print(order_items[order_items['product_id'].str.contains('[A-Z]')]['product_id'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953ba92",
   "metadata": {},
   "source": [
    "Check, Trimming and converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cba2fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "0    9ef432eb6251297304e76186b10a928d\n",
      "1    b0830fb4747a6c6d20dea0b8c802d7ef\n",
      "2    41ce2a54c0b03bf3443c3d931a367089\n",
      "3    f88197465ea7920adcdbec7375364d82\n",
      "4    8ab97904e6daea8866dbdbc4fb7aad2c\n",
      "Name: customer_id, dtype: object\n",
      "0    06b8999e2fba1a1fbc88172c00ba8bc7\n",
      "1    18955e83d337fd6b2def6b18a428ac77\n",
      "2    4e7b3e00288586ebd08712fdd0374a03\n",
      "3    b2b6027bc5c5109e529d4dc6358b12c3\n",
      "4    4f2d8ab171c80ec8364f7c12e35b23ad\n",
      "Name: customer_id, dtype: object\n",
      "0    1e9e8ef04dbcff4541ed26657ea517e5\n",
      "1    3aa071139cb16b67ca9e5dea641aaa2f\n",
      "2    96bd76ec8810374ed1b65e291975717f\n",
      "3    cef67bcfe19066a932b7673e239eb23d\n",
      "4    9dc1a7de274444849c219cff195d0b71\n",
      "Name: product_id, dtype: object\n",
      "0    4244733e06e7ecb4970a6e2683c13e61\n",
      "1    e5f2d52b802189ee658865ca93d83a8f\n",
      "2    c777355d18b72b67abbeef9df44fd0fd\n",
      "3    7634da152a4610f1595efa32f14722fc\n",
      "4    ac6c3623068f30de03045865e4e10089\n",
      "Name: product_id, dtype: object\n",
      "0    3442f8959a84dea7ee197c632cb2df15\n",
      "1    d1b65fc7debc3361ea86b5f14c68d2e2\n",
      "2    ce3ad9de960102d0677a81f5d0bb7b2d\n",
      "3    c0f3eea2e14555b6faeea3dd58c1b1c3\n",
      "4    51a04a8a6bdcb23deccc82b0b80742cf\n",
      "Name: seller_id, dtype: object\n",
      "0    48436dade18ac8b2bce089ec2a041202\n",
      "1    dd7ddc04e1b6c2c614352b383efe2d36\n",
      "2    5b51032eddd242adc84c38acab88f23d\n",
      "3    9d7a1d34a5052409006425275ba1c2b4\n",
      "4    df560393f3a51e74553ab94004ba5c87\n",
      "Name: seller_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the key columns before trimming and converting to lowercase\n",
    "print(\"Before cleaning:\")\n",
    "print(orders['customer_id'].head())\n",
    "print(customers['customer_id'].head())\n",
    "\n",
    "print(products['product_id'].head())\n",
    "print(order_items['product_id'].head())\n",
    "\n",
    "print(sellers['seller_id'].head())\n",
    "print(order_items['seller_id'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181890fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "0    9ef432eb6251297304e76186b10a928d\n",
      "1    b0830fb4747a6c6d20dea0b8c802d7ef\n",
      "2    41ce2a54c0b03bf3443c3d931a367089\n",
      "3    f88197465ea7920adcdbec7375364d82\n",
      "4    8ab97904e6daea8866dbdbc4fb7aad2c\n",
      "Name: customer_id, dtype: object\n",
      "0    06b8999e2fba1a1fbc88172c00ba8bc7\n",
      "1    18955e83d337fd6b2def6b18a428ac77\n",
      "2    4e7b3e00288586ebd08712fdd0374a03\n",
      "3    b2b6027bc5c5109e529d4dc6358b12c3\n",
      "4    4f2d8ab171c80ec8364f7c12e35b23ad\n",
      "Name: customer_id, dtype: object\n",
      "0    1e9e8ef04dbcff4541ed26657ea517e5\n",
      "1    3aa071139cb16b67ca9e5dea641aaa2f\n",
      "2    96bd76ec8810374ed1b65e291975717f\n",
      "3    cef67bcfe19066a932b7673e239eb23d\n",
      "4    9dc1a7de274444849c219cff195d0b71\n",
      "Name: product_id, dtype: object\n",
      "0    4244733e06e7ecb4970a6e2683c13e61\n",
      "1    e5f2d52b802189ee658865ca93d83a8f\n",
      "2    c777355d18b72b67abbeef9df44fd0fd\n",
      "3    7634da152a4610f1595efa32f14722fc\n",
      "4    ac6c3623068f30de03045865e4e10089\n",
      "Name: product_id, dtype: object\n",
      "0    3442f8959a84dea7ee197c632cb2df15\n",
      "1    d1b65fc7debc3361ea86b5f14c68d2e2\n",
      "2    ce3ad9de960102d0677a81f5d0bb7b2d\n",
      "3    c0f3eea2e14555b6faeea3dd58c1b1c3\n",
      "4    51a04a8a6bdcb23deccc82b0b80742cf\n",
      "Name: seller_id, dtype: object\n",
      "0    48436dade18ac8b2bce089ec2a041202\n",
      "1    dd7ddc04e1b6c2c614352b383efe2d36\n",
      "2    5b51032eddd242adc84c38acab88f23d\n",
      "3    9d7a1d34a5052409006425275ba1c2b4\n",
      "4    df560393f3a51e74553ab94004ba5c87\n",
      "Name: seller_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Trim whitespaces and ensure consistent case in key columns\n",
    "orders['customer_id'] = orders['customer_id'].str.strip().str.lower()\n",
    "customers['customer_id'] = customers['customer_id'].str.strip().str.lower()\n",
    "\n",
    "products['product_id'] = products['product_id'].str.strip().str.lower()\n",
    "order_items['product_id'] = order_items['product_id'].str.strip().str.lower()\n",
    "\n",
    "sellers['seller_id'] = sellers['seller_id'].str.strip().str.lower()\n",
    "order_items['seller_id'] = order_items['seller_id'].str.strip().str.lower()\n",
    "\n",
    "\n",
    "# Display the same key columns after trimming and converting to lowercase\n",
    "print(\"After cleaning:\")\n",
    "print(orders['customer_id'].head())\n",
    "print(customers['customer_id'].head())\n",
    "\n",
    "print(products['product_id'].head())\n",
    "print(order_items['product_id'].head())\n",
    "\n",
    "print(sellers['seller_id'].head())\n",
    "print(order_items['seller_id'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284580c",
   "metadata": {},
   "source": [
    "# Merge/Join the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f9a4a",
   "metadata": {},
   "source": [
    "After cleaning the data and removing duplicates, merge the datasets based on keys like \n",
    "order_id, customer_id, product_id, etc.\n",
    "Let’s merge the relevant datasets step by step. You can start with merging the orders, customers, and order_items datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc4d623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "2  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "3  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "4  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "1    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "2    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "3    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "4    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "2          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "3          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "4          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "\n",
      "  order_estimated_delivery_date                customer_unique_id  \\\n",
      "0                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
      "1                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
      "2                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
      "3                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
      "4                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
      "\n",
      "   customer_zip_code_prefix  ... payment_sequential payment_type  \\\n",
      "0                      3149  ...                1.0  credit_card   \n",
      "1                      3149  ...                3.0      voucher   \n",
      "2                      3149  ...                2.0      voucher   \n",
      "3                      3149  ...                1.0  credit_card   \n",
      "4                      3149  ...                3.0      voucher   \n",
      "\n",
      "   payment_installments payment_value                         review_id  \\\n",
      "0                   1.0         18.12  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "1                   1.0          2.00  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "2                   1.0         18.59  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "3                   1.0         18.12  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "4                   1.0          2.00  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "\n",
      "  review_score  review_comment_title  \\\n",
      "0          4.0              No Title   \n",
      "1          4.0              No Title   \n",
      "2          4.0              No Title   \n",
      "3          4.0              No Title   \n",
      "4          4.0              No Title   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0  Não testei o produto ainda, mas ele veio corre...           2017-10-11   \n",
      "1  Não testei o produto ainda, mas ele veio corre...           2017-10-11   \n",
      "2  Não testei o produto ainda, mas ele veio corre...           2017-10-11   \n",
      "3  Não testei o produto ainda, mas ele veio corre...           2017-10-11   \n",
      "4  Não testei o produto ainda, mas ele veio corre...           2017-10-11   \n",
      "\n",
      "   review_answer_timestamp  \n",
      "0      2017-10-12 03:43:48  \n",
      "1      2017-10-12 03:43:48  \n",
      "2      2017-10-12 03:43:48  \n",
      "3      2017-10-12 03:43:48  \n",
      "4      2017-10-12 03:43:48  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge orders and customers datasets\n",
    "\n",
    "# Need customer information to understand customer behavior.\n",
    "# Using a left join keeps all orders, even if some orders may not have associated customer details\n",
    "\n",
    "merged_data = pd.merge(orders, customers, on='customer_id', how='left')\n",
    "\n",
    "# Step 2: Merge the result with order_items\n",
    "\n",
    "# Each order may have one or more items. To analyze what items were purchased in each order join on order_id.\n",
    "# Left join keeps all orders, even if some orders don't have items.\n",
    "\n",
    "merged_data = pd.merge(merged_data, order_items, on='order_id', how='left')\n",
    "\n",
    "# Step 3: Merge with products dataset\n",
    "\n",
    "#  need to enrich the dataset with product information.\n",
    "# Each order item is linked to a specific product by product_id\n",
    "# You use a left join to ensure that all items from the order_items table are retained, even if some items have missing product details\n",
    "# f a matching product_id is not found, the product-related columns will be filled with NaN\n",
    "\n",
    "merged_data = pd.merge(merged_data, products, on='product_id', how='left')\n",
    "\n",
    "# Step 4: Merge with geolocation dataset\n",
    "\n",
    "# need geolocation data (latitude, longitude) to perform geographic analyses on where customers are locate\n",
    "# join the customer_zip_code_prefix in orders with the geolocation_zip_code_prefix in the geolocation dataset.\n",
    "\n",
    "merged_data = pd.merge(merged_data, geolocation_cleaned, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
    "\n",
    "# Step 5: Merge with sellers dataset\n",
    "\n",
    "# Sellers are crucial in the marketplace model, so need to merge their details.\n",
    "#  Left join ensures that all orders, including those without seller information.\n",
    "\n",
    "merged_data = pd.merge(merged_data, sellers, on='seller_id', how='left')\n",
    "\n",
    "# Step 6: Merge with order_payments and order_reviews if necessary\n",
    "\n",
    "# Payment and review information is important to understand order success and customer feedback.\n",
    "# Left join ensures that all orders are kept, even if some orders do not have associated payment or review information.\n",
    "\n",
    "merged_data = pd.merge(merged_data, order_payments, on='order_id', how='left')\n",
    "merged_data = pd.merge(merged_data, order_reviews, on='order_id', how='left')\n",
    "\n",
    "# Verify the merged dataset\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d5505",
   "metadata": {},
   "source": [
    "# Data Transformation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1babd",
   "metadata": {},
   "source": [
    "Data transformation involves modifying existing data into a new form that is easier to work with for analysis or visualization. \n",
    "The focus here is on:\n",
    "\n",
    "Creating new columns based on existing data.\n",
    "Standardizing data types.\n",
    "Handling skewness in the data if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1369b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Processing Time:\n",
      "  order_purchase_timestamp   order_approved_at  order_processing_time\n",
      "0      2017-10-02 10:56:33 2017-10-02 11:07:15                      0\n",
      "1      2018-07-24 20:41:37 2018-07-26 03:24:27                      1\n",
      "2      2018-08-08 08:38:49 2018-08-08 08:55:23                      0\n",
      "3      2017-11-18 19:28:06 2017-11-18 19:45:59                      0\n",
      "4      2018-02-13 21:18:39 2018-02-13 22:20:29                      0\n"
     ]
    }
   ],
   "source": [
    "# Order Processing Time: Calculate the difference between when the order was purchased and when it was approved.\n",
    "\n",
    "# Calculate order processing time (in days)\n",
    "orders['order_processing_time'] = (orders['order_approved_at'] - orders['order_purchase_timestamp']).dt.days\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "print(\"Order Processing Time:\")\n",
    "print(orders[['order_purchase_timestamp', 'order_approved_at', 'order_processing_time']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137e4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e87eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Order Value:\n",
      "    price  freight_value  total_order_value\n",
      "0   58.90          13.29              72.19\n",
      "1  239.90          19.93             259.83\n",
      "2  199.00          17.87             216.87\n",
      "3   12.99          12.79              25.78\n",
      "4  199.90          18.14             218.04\n"
     ]
    }
   ],
   "source": [
    "# Total Order Value: Combine the price and freight_value in the order_items dataset to get the total order value.\n",
    "\n",
    "# Calculate total order value\n",
    "order_items['total_order_value'] = order_items['price'] + order_items['freight_value']\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "print(\"Total Order Value:\")\n",
    "print(order_items[['price', 'freight_value', 'total_order_value']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "639fbfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipping Time:\n",
      "  order_delivered_customer_date order_estimated_delivery_date  shipping_time\n",
      "0           2017-10-10 21:25:13                    2017-10-18             -8\n",
      "1           2018-08-07 15:27:45                    2018-08-13             -6\n",
      "2           2018-08-17 18:06:29                    2018-09-04            -18\n",
      "3           2017-12-02 00:28:42                    2017-12-15            -13\n",
      "4           2018-02-16 18:17:02                    2018-02-26            -10\n"
     ]
    }
   ],
   "source": [
    "# Shipping Time: Calculate the difference between the estimated delivery date and the actual customer delivery date.\n",
    "\n",
    "# Calculate shipping time (in days)\n",
    "orders['shipping_time'] = (orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']).dt.days\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "print(\"Shipping Time:\")\n",
    "print(orders[['order_delivered_customer_date', 'order_estimated_delivery_date', 'shipping_time']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a22a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_delivered_customer_date order_estimated_delivery_date  shipping_time\n",
      "0           2017-10-10 21:25:13                    2017-10-18              1\n",
      "1           2018-08-07 15:27:45                    2018-08-13              1\n",
      "2           2018-08-17 18:06:29                    2018-09-04              1\n",
      "3           2017-12-02 00:28:42                    2017-12-15              1\n",
      "4           2018-02-16 18:17:02                    2018-02-26              1\n"
     ]
    }
   ],
   "source": [
    "# Calculate shipping time (in days)\n",
    "orders['shipping_time'] = (orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']).dt.days\n",
    "\n",
    "# Replace negative and zero shipping times with 1\n",
    "orders.loc[orders['shipping_time'] < 1, 'shipping_time'] = 1\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "print(orders[['order_delivered_customer_date', 'order_estimated_delivery_date', 'shipping_time']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8536c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a7e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Components (Year, Month, Day of Week):\n",
      "  order_purchase_timestamp  purchase_year  purchase_month  \\\n",
      "0      2017-10-02 10:56:33           2017              10   \n",
      "1      2018-07-24 20:41:37           2018               7   \n",
      "2      2018-08-08 08:38:49           2018               8   \n",
      "3      2017-11-18 19:28:06           2017              11   \n",
      "4      2018-02-13 21:18:39           2018               2   \n",
      "\n",
      "   purchase_day_of_week  \n",
      "0                     0  \n",
      "1                     1  \n",
      "2                     2  \n",
      "3                     5  \n",
      "4                     1  \n"
     ]
    }
   ],
   "source": [
    "# Extract Date Components: Extract useful information such as year, month, and day of the week from order_purchase_timestamp for time-based analysis.\n",
    "\n",
    "# Extract year, month, and day of the week from purchase timestamp\n",
    "orders['purchase_year'] = orders['order_purchase_timestamp'].dt.year\n",
    "orders['purchase_month'] = orders['order_purchase_timestamp'].dt.month\n",
    "orders['purchase_day_of_week'] = orders['order_purchase_timestamp'].dt.dayofweek\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "print(\"Date Components (Year, Month, Day of Week):\")\n",
    "print(orders[['order_purchase_timestamp', 'purchase_year', 'purchase_month', 'purchase_day_of_week']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595e765",
   "metadata": {},
   "source": [
    "# Calculate Total Spend per Customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc8f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id  total_spend\n",
      "0  00012a2ce6f8dcda20d059ce98491703       114.74\n",
      "1  000161a058600d5901f007fab4c27140        67.41\n",
      "2  0001fd6190edaaf884bcaf3d49edf079       195.42\n",
      "3  0002414f95344307404f0ace7a26f1d5       179.35\n",
      "4  000379cdec625522490c315e70c7a9fb       107.01\n"
     ]
    }
   ],
   "source": [
    "# Merge orders with order_items to associate orders with customers\n",
    "merged_data = pd.merge(orders, order_items, on='order_id', how='left')\n",
    "\n",
    "# Calculate total spend per customer\n",
    "total_spend_per_customer = merged_data.groupby('customer_id')['total_order_value'].sum().reset_index()\n",
    "total_spend_per_customer.columns = ['customer_id', 'total_spend']\n",
    "\n",
    "# Check the result\n",
    "print(total_spend_per_customer.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003dceb1",
   "metadata": {},
   "source": [
    "# Calculate Number of Orders per Customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1a2423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id  number_of_orders\n",
      "0  00012a2ce6f8dcda20d059ce98491703                 1\n",
      "1  000161a058600d5901f007fab4c27140                 1\n",
      "2  0001fd6190edaaf884bcaf3d49edf079                 1\n",
      "3  0002414f95344307404f0ace7a26f1d5                 1\n",
      "4  000379cdec625522490c315e70c7a9fb                 1\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of orders per customer\n",
    "number_of_orders_per_customer = merged_data.groupby('customer_id')['order_id'].nunique().reset_index()\n",
    "number_of_orders_per_customer.columns = ['customer_id', 'number_of_orders']\n",
    "\n",
    "# Check the result\n",
    "print(number_of_orders_per_customer.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f145fe",
   "metadata": {},
   "source": [
    "# Calculate Purchase Frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47bd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id  total_spend  number_of_orders  \\\n",
      "0  00012a2ce6f8dcda20d059ce98491703       114.74                 1   \n",
      "1  000161a058600d5901f007fab4c27140        67.41                 1   \n",
      "2  0001fd6190edaaf884bcaf3d49edf079       195.42                 1   \n",
      "3  0002414f95344307404f0ace7a26f1d5       179.35                 1   \n",
      "4  000379cdec625522490c315e70c7a9fb       107.01                 1   \n",
      "\n",
      "       first_purchase       last_purchase  purchase_frequency  \n",
      "0 2017-11-14 16:08:26 2017-11-14 16:08:26                 0.0  \n",
      "1 2017-07-16 09:40:32 2017-07-16 09:40:32                 0.0  \n",
      "2 2017-02-28 11:06:43 2017-02-28 11:06:43                 0.0  \n",
      "3 2017-08-16 13:09:20 2017-08-16 13:09:20                 0.0  \n",
      "4 2018-04-02 13:42:17 2018-04-02 13:42:17                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the first and last purchase date for each customer\n",
    "customer_purchase_times = merged_data.groupby('customer_id').agg(\n",
    "    first_purchase=('order_purchase_timestamp', 'min'),\n",
    "    last_purchase=('order_purchase_timestamp', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Merge the number_of_orders and total_spend with the customer_purchase_times dataframe\n",
    "customer_segmentation = pd.merge(total_spend_per_customer, number_of_orders_per_customer, on='customer_id')\n",
    "customer_segmentation = pd.merge(customer_segmentation, customer_purchase_times, on='customer_id')\n",
    "\n",
    "# Calculate purchase frequency (days between first and last purchase divided by number of orders)\n",
    "customer_segmentation['purchase_frequency'] = (\n",
    "    (customer_segmentation['last_purchase'] - customer_segmentation['first_purchase']).dt.days\n",
    "    / customer_segmentation['number_of_orders']\n",
    ")\n",
    "\n",
    "# Check the result\n",
    "print(customer_segmentation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee07a4a",
   "metadata": {},
   "source": [
    "# Additional Aggregates (Revenue per Product Category & State):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e6984",
   "metadata": {},
   "source": [
    " Total Revenue per Product Category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8bbe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_category_name  total_revenue\n",
      "0                    Unknown      207705.09\n",
      "1  agro_industria_e_comercio       78374.07\n",
      "2                  alimentos       36664.44\n",
      "3          alimentos_bebidas       19687.47\n",
      "4                      artes       28247.81\n"
     ]
    }
   ],
   "source": [
    "# Merge products dataset with order_items to associate products with orders\n",
    "merged_products = pd.merge(order_items, products, on='product_id', how='left')\n",
    "\n",
    "# Calculate total revenue per product category\n",
    "total_revenue_per_category = merged_products.groupby('product_category_name')['total_order_value'].sum().reset_index()\n",
    "total_revenue_per_category.columns = ['product_category_name', 'total_revenue']\n",
    "\n",
    "# Check the result\n",
    "print(total_revenue_per_category.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29fc3e",
   "metadata": {},
   "source": [
    " Total Revenue per Customer State:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ec249bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_state  total_revenue\n",
      "0             AC       19575.33\n",
      "1             AL       94172.49\n",
      "2             AM       27585.47\n",
      "3             AP       16141.81\n",
      "4             BA      591137.81\n"
     ]
    }
   ],
   "source": [
    "# Merge customers dataset with merged_data to get customer state associated with each order\n",
    "merged_geo = pd.merge(merged_data, customers, on='customer_id', how='left')\n",
    "\n",
    "# Calculate total revenue per customer state\n",
    "total_revenue_per_state = merged_geo.groupby('customer_state')['total_order_value'].sum().reset_index()\n",
    "total_revenue_per_state.columns = ['customer_state', 'total_revenue']\n",
    "\n",
    "# Check the result\n",
    "print(total_revenue_per_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846690d",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3becc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Sales (Total Order Value):\n",
      "count    112650.000000\n",
      "mean        140.644059\n",
      "std         190.724394\n",
      "min           6.080000\n",
      "25%          55.220000\n",
      "50%          92.320000\n",
      "75%         157.937500\n",
      "max        6929.310000\n",
      "Name: total_order_value, dtype: float64\n",
      "Descriptive Statistics for Freight Value:\n",
      "count    112650.000000\n",
      "mean         19.990320\n",
      "std          15.806405\n",
      "min           0.000000\n",
      "25%          13.080000\n",
      "50%          16.260000\n",
      "75%          21.150000\n",
      "max         409.680000\n",
      "Name: freight_value, dtype: float64\n",
      "Descriptive Statistics for Total Spend per Customer:\n",
      "count    96475.000000\n",
      "mean       159.823264\n",
      "std        218.797315\n",
      "min          9.590000\n",
      "25%         61.850000\n",
      "50%        105.280000\n",
      "75%        176.260000\n",
      "max      13664.080000\n",
      "Name: total_spend, dtype: float64\n",
      "Descriptive Statistics for Number of Orders per Customer:\n",
      "count    96475.0\n",
      "mean         1.0\n",
      "std          0.0\n",
      "min          1.0\n",
      "25%          1.0\n",
      "50%          1.0\n",
      "75%          1.0\n",
      "max          1.0\n",
      "Name: number_of_orders, dtype: float64\n",
      "Descriptive Statistics for Purchase Frequency:\n",
      "count    96475.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: purchase_frequency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Descriptive Statistics for Sales (Total Order Value)\n",
    "sales_stats = order_items['total_order_value'].describe()\n",
    "print(\"Descriptive Statistics for Sales (Total Order Value):\")\n",
    "print(sales_stats)\n",
    "\n",
    "# Descriptive Statistics for Freight Value\n",
    "freight_stats = order_items['freight_value'].describe()\n",
    "print(\"Descriptive Statistics for Freight Value:\")\n",
    "print(freight_stats)\n",
    "\n",
    "# Descriptive Statistics for Customer Segments\n",
    "total_spend_stats = customer_segmentation['total_spend'].describe()\n",
    "orders_per_customer_stats = customer_segmentation['number_of_orders'].describe()\n",
    "purchase_frequency_stats = customer_segmentation['purchase_frequency'].describe()\n",
    "\n",
    "print(\"Descriptive Statistics for Total Spend per Customer:\")\n",
    "print(total_spend_stats)\n",
    "print(\"Descriptive Statistics for Number of Orders per Customer:\")\n",
    "print(orders_per_customer_stats)\n",
    "print(\"Descriptive Statistics for Purchase Frequency:\")\n",
    "print(purchase_frequency_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc759c",
   "metadata": {},
   "source": [
    "# Export Cleaned Data For Further Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9ef7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets have been successfully exported as CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned orders data\n",
    "orders.to_csv('cleaned_orders.csv', index=False)\n",
    "\n",
    "# Export cleaned order items data\n",
    "order_items.to_csv('cleaned_order_items.csv', index=False)\n",
    "\n",
    "# Export cleaned customers data\n",
    "customers.to_csv('cleaned_customers.csv', index=False)\n",
    "\n",
    "# Export cleaned products data\n",
    "products.to_csv('cleaned_products.csv', index=False)\n",
    "\n",
    "# Export customer segmentation data (if you have this created)\n",
    "customer_segmentation.to_csv('customer_segmentation.csv', index=False)\n",
    "\n",
    "# You can print a confirmation message after the exports\n",
    "print(\"All datasets have been successfully exported as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89d1370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All additional datasets have been successfully exported as CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned order_reviews data\n",
    "order_reviews.to_csv('cleaned_order_reviews.csv', index=False)\n",
    "\n",
    "# Export cleaned order_payments data\n",
    "order_payments.to_csv('cleaned_order_payments.csv', index=False)\n",
    "\n",
    "# Export cleaned sellers data\n",
    "sellers.to_csv('cleaned_sellers.csv', index=False)\n",
    "\n",
    "# Export cleaned geolocation data\n",
    "geolocation_cleaned.to_csv('cleaned_geolocation.csv', index=False)\n",
    "\n",
    "print(\"All additional datasets have been successfully exported as CSV files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
